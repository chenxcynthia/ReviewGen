{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7732db40",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-da3b4954c199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# from torchvision.datasets import CIFAR10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maccelerate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccelerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "\n",
    "# from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from collections import OrderedDict\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0c2e6",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f9613-78a2-4822-983e-76594fab462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b838c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (1.22.1)\n",
      "Requirement already satisfied: multiprocess in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: xxhash in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: packaging in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: aiohttp in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets) (3.7.4)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from aiohttp->datasets) (3.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from aiohttp->datasets) (4.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: filelock in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (0.1.97)\n",
      "Requirement already satisfied: rouge_score in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from rouge_score) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from rouge_score) (1.22.1)\n",
      "Requirement already satisfied: absl-py in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from rouge_score) (0.15.0)\n",
      "Requirement already satisfied: nltk in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from rouge_score) (3.6.1)\n",
      "Requirement already satisfied: regex in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from nltk->rouge_score) (2021.4.4)\n",
      "Requirement already satisfied: click in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from nltk->rouge_score) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from nltk->rouge_score) (4.65.0)\n",
      "Requirement already satisfied: joblib in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from nltk->rouge_score) (1.0.1)\n",
      "Requirement already satisfied: wandb in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (0.10.18)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (5.0.1)\n",
      "Requirement already satisfied: Click>=7.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (3.1.13)\n",
      "Requirement already satisfied: pathtools in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: PyYAML in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (5.9.2)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (0.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (3.20.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.4)\n",
      "Requirement already satisfied: bert-score in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (0.3.13)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (1.2.4)\n",
      "Requirement already satisfied: numpy in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (1.22.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (20.9)\n",
      "Requirement already satisfied: matplotlib in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (3.3.4)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (4.65.0)\n",
      "Requirement already satisfied: requests in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (2.25.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (1.12.1)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (4.27.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from packaging>=20.9->bert-score) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (4.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (2021.4.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.12.1)\n",
      "Requirement already satisfied: filelock in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.13.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from matplotlib->bert-score) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from matplotlib->bert-score) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from matplotlib->bert-score) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->bert-score) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->bert-score) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->bert-score) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->bert-score) (3.0.4)\n",
      "Requirement already satisfied: evaluate in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from evaluate) (1.22.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: pandas in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from evaluate) (1.2.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from evaluate) (2023.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from evaluate) (0.12.1)\n",
      "Requirement already satisfied: dill in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from evaluate) (2.10.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from evaluate) (2.25.1)\n",
      "Requirement already satisfied: packaging in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from evaluate) (20.9)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (8.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: aiohttp in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.7.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (20.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.3.0)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (3.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.1.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.3)\n",
      "Requirement already satisfied: filelock in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from packaging->evaluate) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from pandas->evaluate) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from pandas->evaluate) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
      "Requirement already satisfied: transformers in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (4.27.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: requests in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers) (1.22.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: filelock in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->transformers) (3.0.4)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.27.2\n",
      "    Uninstalling transformers-4.27.2:\n",
      "      Successfully uninstalled transformers-4.27.2\n",
      "Successfully installed transformers-4.28.1\n",
      "Requirement already satisfied: bert-score in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (0.3.13)\n",
      "Requirement already satisfied: requests in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (2.25.1)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (4.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (20.9)\n",
      "Requirement already satisfied: torch>=1.0.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (1.12.1)\n",
      "Requirement already satisfied: numpy in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (1.22.1)\n",
      "Requirement already satisfied: matplotlib in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (3.3.4)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bert-score) (1.2.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from packaging>=20.9->bert-score) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (2021.4.4)\n",
      "Requirement already satisfied: filelock in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.12.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from matplotlib->bert-score) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from matplotlib->bert-score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from matplotlib->bert-score) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->bert-score) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->bert-score) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->bert-score) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->bert-score) (3.0.4)\n",
      "zsh:1: no matches found: accelerate[torch]\n",
      "Collecting bertviz\n",
      "  Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bertviz) (0.1.97)\n",
      "Requirement already satisfied: transformers>=2.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bertviz) (4.28.1)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.26.129-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 13.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bertviz) (2021.4.4)\n",
      "Requirement already satisfied: requests in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bertviz) (2.25.1)\n",
      "Requirement already satisfied: torch>=1.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bertviz) (1.12.1)\n",
      "Requirement already satisfied: tqdm in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from bertviz) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from torch>=1.0->bertviz) (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=2.0->bertviz) (1.22.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=2.0->bertviz) (0.13.2)\n",
      "Requirement already satisfied: filelock in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=2.0->bertviz) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=2.0->bertviz) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=2.0->bertviz) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from transformers>=2.0->bertviz) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from packaging>=20.0->transformers>=2.0->bertviz) (2.4.7)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 14.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.30.0,>=1.29.129\n",
      "  Downloading botocore-1.29.129-py3-none-any.whl (10.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.7 MB 14.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.129->boto3->bertviz) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.129->boto3->bertviz) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.129->boto3->bertviz) (1.15.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->bertviz) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->bertviz) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/erichansen/.conda/envs/data-sci/lib/python3.9/site-packages (from requests->bertviz) (2022.12.7)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, bertviz\n",
      "Successfully installed bertviz-1.4.0 boto3-1.26.129 botocore-1.29.129 jmespath-1.0.1 s3transfer-0.6.1\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "\n",
    "! pip install datasets\n",
    "! pip install sentencepiece\n",
    "! pip install rouge_score\n",
    "! pip install wandb\n",
    "! pip install bert-score\n",
    "! pip install evaluate\n",
    "! pip install transformers -U\n",
    "! pip install bert-score\n",
    "! pip install accelerate[torch]\n",
    "! pip install bertviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb17007c",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d46053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import utils\n",
    "\n",
    "utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f0f4da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7615d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2ad741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = './'\n",
    "\n",
    "input_filename = 'all_preprocessed_data_with_citations_aspect_scores.csv'\n",
    "# 'preprocessed_data_no_nans_1k.csv' \n",
    "\n",
    "# Full DataSet Size is 15000 (review, paper), but due to GPU cost + time constraints, we use a sub-sample of 5000 reviews\n",
    "sample_size = 1000 \n",
    "\n",
    "seed = 282\n",
    "\n",
    "# Specify Extraction Method used to Generate Training Text from Papers\n",
    "# Either: (intro, ce_extract, hybrid)\n",
    "extraction_method = 'hybrid'\n",
    "\n",
    "# Maximum Token Length of Paper Extracts Used To Train Model\n",
    "max_paper_extract_length = 1024 # 1024 is the max input size of a BART model\n",
    "max_review_length = 1024\n",
    "min_text_length = 100\n",
    "\n",
    "# Pre-Trained Hugging Face Seq2Seq Transformers Model\n",
    "pre_trained_model_checkpoint = \"facebook/bart-large-cnn\"\n",
    "ner_model_checkpoint = workdir + 'seqlab_final'\n",
    "\n",
    "# Summarization Task Configuration\n",
    "summarization_params = {\n",
    "    \"summarization\": {\n",
    "        \"early_stopping\": True,\n",
    "        \"length_penalty\": 2.0, # BART (favor longer sequences)\n",
    "        \"max_length\": max_review_length,\n",
    "        \"min_length\": min_text_length,\n",
    "        \"no_repeat_ngram_size\": 3, # BART default\n",
    "        \"num_beams\": 4 # BART default\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c210aeeb",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b82b1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets, DatasetDict, Dataset, load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load input data (post-extraction and pre-processing to downsample paper text)\n",
    "all_input_df = pd.read_csv(workdir + input_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06a3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load Tokenizer used with the corresponding pre-trained models\n",
    "ner_tokenizer = AutoTokenizer.from_pretrained(ner_model_checkpoint)\n",
    "\n",
    "bart_tokenizer = AutoTokenizer.from_pretrained(pre_trained_model_checkpoint, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91b0837d-824b-4baa-8e20-ccb9b9a86807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mse_columns(df):\n",
    "    for col in ['rating', 'logCitNum', 'confidence']:\n",
    "        df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de9d6434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22882, 38)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(workdir + 'seqlab_final/config.json', 'r') as infile:\n",
    "    config_js = json.load(infile)\n",
    "\n",
    "all_input_df = all_input_df[~all_input_df['ce_extract'].isna()]\n",
    "all_input_df['tk_labels'] = all_input_df['tk_labels'].apply(eval)\n",
    "all_input_df['tokens'] = all_input_df['tokens'].apply(eval)\n",
    "all_input_df['tk_label_nums'] = all_input_df['tk_labels'].apply(lambda r: [config_js['label2id'][lbl] for lbl in r])\n",
    "all_input_df = all_input_df # [not currently used] filter_on_token_length(df_exp, tokenizer, extraction_method)\n",
    "\n",
    "all_input_df = normalize_mse_columns(all_input_df)\n",
    "\n",
    "if sample_size:\n",
    "    sample_df = all_input_df.sample(sample_size, random_state=seed)\n",
    "else:\n",
    "    sample_df = all_input_df\n",
    "\n",
    "all_input_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44218f70-883e-4227-b5b6-74160181602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_no_nan = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f69d6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df_no_nan = all_input_df.copy(deep=True)\n",
    "\n",
    "input_df_no_nan = input_df_no_nan[input_df_no_nan['decision_label'].notna()]\n",
    "input_df_no_nan = input_df_no_nan[input_df_no_nan['confidence'].notna()]\n",
    "input_df_no_nan = input_df_no_nan[input_df_no_nan['logCitNum'].notna()]\n",
    "input_df_no_nan = input_df_no_nan[input_df_no_nan['rating'].notna()]\n",
    "input_df_no_nan = input_df_no_nan[~input_df_no_nan['ce_extract'].isna()]\n",
    "\n",
    "if use_no_nan:\n",
    "    if sample_size:\n",
    "        sample_df = input_df_no_nan.sample(sample_size, random_state=seed)\n",
    "    else:\n",
    "        sample_df = input_df_no_nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bacc435c-6ec8-40b1-853e-a593eb60442d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 38)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73806d45-7e55-44a2-8984-5be4f2ab437e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision_label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>logCitNum</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.234833</td>\n",
       "      <td>-0.006162</td>\n",
       "      <td>0.310872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.492261</td>\n",
       "      <td>0.906558</td>\n",
       "      <td>1.180253</td>\n",
       "      <td>0.785742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.872757</td>\n",
       "      <td>-2.204442</td>\n",
       "      <td>-2.095345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.646690</td>\n",
       "      <td>-0.808242</td>\n",
       "      <td>-0.015642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466344</td>\n",
       "      <td>0.102059</td>\n",
       "      <td>0.504284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.466344</td>\n",
       "      <td>0.802824</td>\n",
       "      <td>1.024210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.579377</td>\n",
       "      <td>2.938793</td>\n",
       "      <td>2.583987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       decision_label   confidence    logCitNum       rating\n",
       "count     1000.000000  1000.000000  1000.000000  1000.000000\n",
       "mean         0.411000     0.234833    -0.006162     0.310872\n",
       "std          0.492261     0.906558     1.180253     0.785742\n",
       "min          0.000000    -2.872757    -2.204442    -2.095345\n",
       "25%          0.000000    -0.646690    -0.808242    -0.015642\n",
       "50%          0.000000     0.466344     0.102059     0.504284\n",
       "75%          1.000000     0.466344     0.802824     1.024210\n",
       "max          1.000000     1.579377     2.938793     2.583987"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df[['decision_label', 'confidence', 'logCitNum', 'rating']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59e4fc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5882, 38)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df_no_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e0b561d-05b0-46b3-a7af-0692cca47cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b990fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = Dataset.from_pandas(sample_df)\n",
    "input_dataset_dict = input_dataset.train_test_split(test_size=0.20, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e153e",
   "metadata": {},
   "source": [
    "## Filter on Token Length & Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9e9bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter on token length [not currently used because it decreases the available \n",
    "# dataset size for the CE_extraction method]\n",
    "def filter_on_token_length(df, tokenizer, text_col, text_min=min_text_length, \n",
    "                           text_max=max_paper_extract_length, review_min=min_text_length, \n",
    "                           review_max=max_review_length):\n",
    "    \n",
    "    def test_length_constraints(txt, tokenizer, mn_length, mx_length):\n",
    "        tokenized_txt = tokenizer(txt, max_length=None, truncation=False)\n",
    "        num_tokens = len(tokenized_txt['input_ids'])\n",
    "\n",
    "        return (num_tokens >= mn_length) and (num_tokens <= mx_length)\n",
    "      \n",
    "    return df[\n",
    "              (df[text_col].apply(lambda s: test_length_constraints(s, tokenizer, text_min, text_max))) &\n",
    "              (df['review'].apply(lambda s: test_length_constraints(s, tokenizer, review_min, review_max)))\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac085deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a0b0f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example, extraction_method='hybrid', device=device):\n",
    "#     print(device)\n",
    "\n",
    "    ## Tokenize the paper extract\n",
    "    if extraction_method == 'intro':\n",
    "        input_text = example['intro']\n",
    "    elif extraction_method == 'ce_extract':\n",
    "        input_text = example['ce_extract']\n",
    "    elif extraction_method == 'hybrid':\n",
    "        input_text = example['abstract'] + example['ce_extract']\n",
    "\n",
    "    model_inputs = bart_tokenizer(\n",
    "        input_text,\n",
    "        max_length=max_paper_extract_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    ## Get Review Tokens and Output\n",
    "    review_tokenized_outputs = bart_tokenizer(\n",
    "        example[\"tokens\"], truncation=True, is_split_into_words=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_review_length\n",
    "    )\n",
    "    all_ner_labels = example[\"tk_label_nums\"]\n",
    "    word_ids = review_tokenized_outputs.word_ids(0)\n",
    "    ner_labels = align_labels_with_tokens(all_ner_labels, word_ids)\n",
    "\n",
    "    # print(len(review_tokenized_outputs['input_ids']))\n",
    "    # print(len(ner_labels))\n",
    "    # print(torch.Tensor(review_tokenized_outputs['input_ids']).shape)\n",
    "    # print(torch.Tensor(ner_labels).shape)\n",
    "    # print(len(model_inputs['input_ids']))\n",
    "\n",
    "    model_inputs['labels'] = torch.tensor(review_tokenized_outputs[\"input_ids\"]).to(device)\n",
    "    model_inputs[\"ner_labels\"] = torch.IntTensor(ner_labels).to(device)\n",
    "    model_inputs[\"input_ids\"] = torch.tensor(model_inputs[\"input_ids\"]).to(device)\n",
    "    model_inputs['attention_mask'] = torch.tensor(model_inputs['attention_mask']).to(device)\n",
    "\n",
    "    # print(type(model_inputs['input_ids']))\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d00debd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset_for_reviews = input_dataset_dict.map(lambda s: \n",
    "   tokenize_and_align_labels(s, extraction_method=extraction_method, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d977cca-c4f7-4fe9-8647-a222b3332f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'labels', 'tokens', 'tk_labels', 'title', 'decision', 'abstract', 'intro', 'conference', 'review', 'decision_label', 'intro_len', 'abstract_len', 'review_len', 'ce_extract', 'ce_extract_len', 'hybrid', 'hybrid_len', 'pid', 'rid', 'uid', 'confidence_str', 'rating_str', 'paper_len', 'conclusion', 'conclusion_len', 'url', 'emails', 'source', 'authors', 'confidence', 'rating', 'decision_binary', 'review_no_whitespace', 'CitNum', 'logCitNum', 'tk_label_nums', '__index_level_0__', 'input_ids', 'attention_mask', 'ner_labels'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'labels', 'tokens', 'tk_labels', 'title', 'decision', 'abstract', 'intro', 'conference', 'review', 'decision_label', 'intro_len', 'abstract_len', 'review_len', 'ce_extract', 'ce_extract_len', 'hybrid', 'hybrid_len', 'pid', 'rid', 'uid', 'confidence_str', 'rating_str', 'paper_len', 'conclusion', 'conclusion_len', 'url', 'emails', 'source', 'authors', 'confidence', 'rating', 'decision_binary', 'review_no_whitespace', 'CitNum', 'logCitNum', 'tk_label_nums', '__index_level_0__', 'input_ids', 'attention_mask', 'ner_labels'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_for_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c64c39",
   "metadata": {},
   "source": [
    "# Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c34e7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class ExtendedSeq2SeqLMOutput(Seq2SeqLMOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits: torch.FloatTensor = None\n",
    "    decision_pred: Optional[torch.FloatTensor] = None # new \n",
    "    confidence_pred: Optional[torch.FloatTensor] = None # new \n",
    "    logCitNum_pred: Optional[torch.FloatTensor] = None # new \n",
    "    rating_pred: Optional[torch.FloatTensor] = None # new \n",
    "    aspect_pred: Optional[torch.FloatTensor] = None # new\n",
    "    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    decoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    decoder_attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    cross_attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    encoder_last_hidden_state: Optional[torch.FloatTensor] = None\n",
    "    encoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    encoder_attentions: Optional[Tuple[torch.FloatTensor]] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21a62b18-ab09-43a2-a6cf-7ac431b8a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_citation=False\n",
    "train_decision=False\n",
    "train_confidence=False\n",
    "train_rating=False\n",
    "train_review=True\n",
    "train_aspect_score=True\n",
    "\n",
    "citation_loss_scale = 4\n",
    "decision_loss_scale = 2\n",
    "rating_loss_scale = 2\n",
    "confidence_loss_scale = 2\n",
    "review_loss_scale = 2\n",
    "aspect_score_loss_scale = 1\n",
    "\n",
    "model_output_name = 'review_ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0df4edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration\n",
    "from transformers import BartConfig\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# extend BartForConditionalGeneration with additional layer to decode one additional output field to BartForConditionalGeneration\n",
    "# how to subclass model and config: https://discuss.huggingface.co/t/subclassing-a-pretrained-model-for-a-new-objective/10521\n",
    "\n",
    "def shift_tokens_right(input_ids, pad_token_id, decoder_start_token_id):\n",
    "    \"\"\"\n",
    "    Shift input ids one token to the right.\n",
    "    \"\"\"\n",
    "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "    shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
    "    shifted_input_ids[:, 0] = decoder_start_token_id\n",
    "\n",
    "    if pad_token_id is None:\n",
    "        raise ValueError(\"self.model.config.pad_token_id has to be defined.\")\n",
    "    # replace possible -100 values in labels by `pad_token_id`\n",
    "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
    "\n",
    "    return shifted_input_ids\n",
    "\n",
    "class ExtendedBart(BartForConditionalGeneration):\n",
    "    def __init__(self, config): \n",
    "        super(ExtendedBart, self).__init__(config) \n",
    "        \n",
    "#         self.device = device\n",
    "        self.conv1 = nn.Conv2d(1, 1, (1, 1024))\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(1, 1, (1, 1024))\n",
    "        self.decision_fc1 = nn.Linear(1024, 4096)\n",
    "        self.decision_fc2 = nn.Linear(4096, 1024)\n",
    "        self.decision_fc3 = nn.Linear(1024, 1)\n",
    "        \n",
    "        self.confidence_fc1 = nn.Linear(1024, 4096)\n",
    "        self.confidence_fc2 = nn.Linear(4096, 1024)\n",
    "        self.confidence_fc3 = nn.Linear(1024, 1)\n",
    "\n",
    "        self.logCitNum_fc1 = nn.Linear(1024, 4096)\n",
    "        self.logCitNum_fc2 = nn.Linear(4096, 1024)\n",
    "        self.logCitNum_fc3 = nn.Linear(1024, 1)\n",
    "\n",
    "        self.rating_fc1 = nn.Linear(1024, 4096)\n",
    "        self.rating_fc2 = nn.Linear(4096, 1024)\n",
    "        self.rating_fc3 = nn.Linear(1024, 1)\n",
    "\n",
    "        self.ner_fc1 = nn.Linear(1024, 4096)\n",
    "        self.ner_fc2 = nn.Linear(4096, 1024)\n",
    "        self.ner_fc3 = nn.Linear(1024, 16)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids = None,\n",
    "        attention_mask = None,\n",
    "        decoder_input_ids = None,\n",
    "        decoder_attention_mask = None,\n",
    "        head_mask = None,\n",
    "        decoder_head_mask = None,\n",
    "        cross_attn_head_mask = None,\n",
    "        encoder_outputs = None,\n",
    "        past_key_values = None,\n",
    "        inputs_embeds = None,\n",
    "        decoder_inputs_embeds = None,\n",
    "        labels = None,\n",
    "        use_cache = None,\n",
    "        output_attentions = None,\n",
    "        output_hidden_states = None,\n",
    "        return_dict = None,\n",
    "        decision_label=None, # new\n",
    "        confidence=None, # new\n",
    "        logCitNum=None, # new\n",
    "        rating=None, # new\n",
    "        ner_labels=None, # new\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if labels is not None:\n",
    "            use_cache = False\n",
    "            if decoder_input_ids is None and decoder_inputs_embeds is None:\n",
    "                decoder_input_ids = shift_tokens_right(\n",
    "                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
    "                )\n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            decoder_head_mask=decoder_head_mask,\n",
    "            cross_attn_head_mask=cross_attn_head_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        lm_logits = self.lm_head(outputs[0])\n",
    "        lm_logits = lm_logits + self.final_logits_bias.to(lm_logits.device)\n",
    "        \n",
    "        masked_lm_loss = 0\n",
    "        decision_pred = None\n",
    "        confidence_pred = None\n",
    "        logCitNum_pred = None\n",
    "        rating_pred = None\n",
    "        ner_pred = None\n",
    "        \n",
    "        hidden_dim = 1024\n",
    "        seq_len = 1024\n",
    "            \n",
    "        if labels is not None:\n",
    "            batch_size = labels.shape[0]\n",
    "            print(batch_size)\n",
    "            \n",
    "            if train_review:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                masked_lm_loss += review_loss_scale * loss_fct(lm_logits.view(-1, self.config.vocab_size), labels.view(-1))    \n",
    "            \n",
    "                print(f'Review Loss: {masked_lm_loss}')\n",
    "                \n",
    "            metadata_pred = outputs.last_hidden_state.view(batch_size, -1, hidden_dim) # something like (1,837, 1024)\n",
    "            seq_length_padding = seq_len-metadata_pred.shape[1]\n",
    "            metadata_pred = F.pad(metadata_pred, (0,0,0, seq_length_padding), \"constant\", 0)  # zero padding first dimension to 1024\n",
    "            metadata_pred = metadata_pred.view(batch_size, 1, seq_len,hidden_dim)\n",
    "            metadata_pred = self.conv1(metadata_pred)\n",
    "            metadata_pred = metadata_pred.view(batch_size, -1)\n",
    "\n",
    "            if train_decision:\n",
    "                # calculate decision probability\n",
    "                # pad logit to 1024 length\n",
    "                decision_pred = self.decision_fc0(metadata_pred)\n",
    "                decision_pred = self.decision_fc1(decision_pred)\n",
    "                decision_pred = self.decision_fc2(decision_pred)\n",
    "                decision_pred = self.decision_fc3(decision_pred)\n",
    "                decision_pred = decision_pred.view(batch_size)\n",
    "                decision_pred = decision_pred.type(torch.FloatTensor)\n",
    "                decision_label = decision_label.type(torch.FloatTensor)\n",
    "                decision_label_loss_fn = nn.BCEWithLogitsLoss()\n",
    "                decision_label_loss = decision_label_loss_fn(decision_pred, decision_label)\n",
    "                masked_lm_loss += decision_loss_scale * decision_label_loss\n",
    "\n",
    "                print(f'Decision Loss: {decision_label_loss}')\n",
    "                \n",
    "\n",
    "            if train_confidence: \n",
    "                # calculate confidence probability via MSE loss\n",
    "                confidence_pred = self.confidence_fc0(metadata_pred)\n",
    "                confidence_pred = self.confidence_fc1(confidence_pred)\n",
    "                confidence_pred = self.confidence_fc2(confidence_pred)\n",
    "                confidence_pred = self.confidence_fc3(confidence_pred)\n",
    "                confidence_pred = confidence_pred.view(batch_size)\n",
    "                confidence_pred = confidence_pred.type(torch.FloatTensor)\n",
    "                confidence_label = confidence.type(torch.FloatTensor)\n",
    "                confidence_label_loss_fn = nn.MSELoss()\n",
    "                confidence_loss = confidence_label_loss_fn(confidence_pred, confidence_label)\n",
    "                masked_lm_loss += confidence_loss_scale * confidence_loss\n",
    "                print(f'Confidence Loss: {confidence_loss}')\n",
    "\n",
    "\n",
    "            if train_citation:\n",
    "                # calculate logCitNum probability via MSE loss\n",
    "                logCitNum_pred = self.logCitNum_fc0(metadata_pred)\n",
    "                logCitNum_pred = self.logCitNum_fc1(logCitNum_pred)\n",
    "                logCitNum_pred = self.logCitNum_fc2(logCitNum_pred)\n",
    "                logCitNum_pred = self.logCitNum_fc3(logCitNum_pred)\n",
    "                logCitNum_pred = logCitNum_pred.view(batch_size)\n",
    "\n",
    "                logCitNum_pred = logCitNum_pred.type(torch.FloatTensor)\n",
    "                logCitNum_label = logCitNum.type(torch.FloatTensor)\n",
    "                logCitNum_label_loss_fn = nn.MSELoss()\n",
    "                logCitNum_loss = logCitNum_label_loss_fn(logCitNum_pred, logCitNum_label)\n",
    "                masked_lm_loss += citation_loss_scale * logCitNum_loss\n",
    "                print(f'Citation Loss: {logCitNum_loss}')\n",
    "\n",
    "\n",
    "            if train_rating:\n",
    "                # calculate rating probability via MSE loss\n",
    "                rating_pred = self.rating_fc0(metadata_pred)\n",
    "                rating_pred = self.rating_fc1(rating_pred)\n",
    "                rating_pred = self.rating_fc2(rating_pred)\n",
    "                rating_pred = self.rating_fc3(rating_pred)\n",
    "                rating_pred = rating_pred.view(batch_size)\n",
    "                rating_pred = rating_pred.type(torch.FloatTensor)\n",
    "                rating_label = rating.type(torch.FloatTensor)\n",
    "                rating_label_loss_fn = nn.MSELoss()\n",
    "                rating_loss = rating_label_loss_fn(rating_pred, rating_label)\n",
    "                masked_lm_loss += rating_loss_scale * rating_loss\n",
    "                print(f'Rating Loss: {rating_loss}')\n",
    "\n",
    "\n",
    "            # calculate per-token aspect score predictions dim: (1024 x 16)\n",
    "            if train_aspect_score:\n",
    "    #             print('insight into ner')\n",
    "                ner_pred = outputs.last_hidden_state.view(batch_size, -1, hidden_dim) # something like (1,837, 1024)\n",
    "                seq_length_padding = seq_len-ner_pred.shape[1]\n",
    "                ner_pred = F.pad(ner_pred, (0,0,0, seq_length_padding), \"constant\", 0)  # zero padding first dimension to 1024\n",
    "                ner_pred = ner_pred.view(batch_size,seq_len,hidden_dim)\n",
    "\n",
    "                ner_pred = self.ner_fc1(ner_pred)\n",
    "                ner_pred = self.ner_fc2(ner_pred)\n",
    "                ner_pred = self.ner_fc3(ner_pred)\n",
    "\n",
    "                ner_pred = ner_pred.view(batch_size, 16, seq_len) # outputs (batch_size, # of classes, seq_len)\n",
    "\n",
    "                ner_labels = ner_labels.view(batch_size, seq_len) # targets: (batch_size, seq_len)\n",
    "\n",
    "                ner_loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "                ner_pred = ner_pred.to(self.device)\n",
    "                ner_labels = ner_labels.to(self.device)\n",
    "\n",
    "                ner_loss = ner_loss_fn(ner_pred, ner_labels)\n",
    "\n",
    "                masked_lm_loss += aspect_score_loss_scale*ner_loss\n",
    "                print(f'NER Loss: {ner_loss}')\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (lm_logits,) + outputs[1:]\n",
    "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
    "\n",
    "        return ExtendedSeq2SeqLMOutput(\n",
    "            loss=masked_lm_loss,\n",
    "            logits=lm_logits,\n",
    "            decision_pred=decision_pred, # update the eval\n",
    "            confidence_pred=confidence_pred, # new \n",
    "            logCitNum_pred=logCitNum_pred,  # new \n",
    "            rating_pred=rating_pred, # new \n",
    "            aspect_pred=ner_pred,  # new \n",
    "            past_key_values=outputs.past_key_values,\n",
    "            decoder_hidden_states=outputs.decoder_hidden_states,\n",
    "            decoder_attentions=outputs.decoder_attentions,\n",
    "            cross_attentions=outputs.cross_attentions,\n",
    "            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
    "            encoder_hidden_states=outputs.encoder_hidden_states,\n",
    "            encoder_attentions=outputs.encoder_attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fd44b",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4cef9ac3-39ac-47d8-b0fb-49b243338989",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_checkpoint = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74199019-a19c-4dc6-9c93-69e75c8cbc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputmodel/review_ner\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model_checkpoint = 'outputmodel/review_ner'\n",
    "\n",
    "pre_trained_model = pre_trained_model_checkpoint if local_checkpoint else \"facebook/bart-large-cnn\"\n",
    "print(pre_trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17e26a5a-1982-4154-a321-0141c1ba0ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'review_ner'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c75d85c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extended_cfg = ExtendedBartConfig()\n",
    "bart_config = BartConfig()\n",
    "model = ExtendedBart(config=bart_config).from_pretrained(pre_trained_model,\n",
    "                                                         max_length=max_review_length, \n",
    "                                                         min_length=min_text_length,\n",
    "                                                         task_specific_params=summarization_params)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32affa",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "131ea2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "import bert_score\n",
    "import evaluate\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")\n",
    "\n",
    "# Compute Evaulation Metric on Seq2Seq Prediction\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred # can I unpack inputs as third variable\n",
    "\n",
    "#     print(\"evaluation\")\n",
    "#     print(predictions.shape)\n",
    "#     print(labels.shape)\n",
    "\n",
    "    # Decode generated summaries into text\n",
    "    decoded_preds = bart_tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, bart_tokenizer.pad_token_id)\n",
    "    # Decode reference summaries into text\n",
    "    decoded_labels = bart_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    # Compute ROUGE scores\n",
    "    rouge_results = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Compute BERT Scores\n",
    "    # https://github.com/Tiiiger/bert_score/blob/master/example/Demo.ipynb\n",
    "    # https://arxiv.org/pdf/1904.09675.pdf\n",
    "    unscaled_bert_scores = bert_score.score(decoded_preds, decoded_labels, lang='en', \n",
    "                                   verbose=False, rescale_with_baseline=False)\n",
    "    bs_prec, bs_recall, bs_f1 = (unscaled_bert_scores[0].mean(), \n",
    "                                 unscaled_bert_scores[1].mean(), \n",
    "                                 unscaled_bert_scores[2].mean())\n",
    "\n",
    "    # Extract the median scores\n",
    "    results = {k: round(v, 4) for k, v in rouge_results.items()}\n",
    "    \n",
    "    results.update({'Raw_BertScore_F1_mean': bs_f1, \n",
    "                    'Raw_BertScore_Recall_mean': bs_recall,\n",
    "                    'Raw_BertScore_Precision_mean': bs_prec,\n",
    "                    })\n",
    "    \n",
    "    scaled_bert_scores = bert_score.score(decoded_preds, decoded_labels, lang='en', \n",
    "                                   verbose=False, rescale_with_baseline=True)\n",
    "    bs_prec, bs_recall, bs_f1 = (scaled_bert_scores[0].mean(), \n",
    "                                 scaled_bert_scores[1].mean(), \n",
    "                                 scaled_bert_scores[2].mean())\n",
    "\n",
    "    results.update({'Scaled_BertScore_F1_mean': bs_f1, \n",
    "                    'Scaled_BertScore_Recall_mean': bs_recall,\n",
    "                    'Scaled_BertScore_Precision_mean': bs_prec,\n",
    "                    })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4bcd85",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf0ffc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "# Selected based on Hugging Face Guide & Confirmed with validation on small samples\n",
    "num_train_epochs = 5\n",
    "learning_rate = 5.0e-5\n",
    "weight_decay = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d91640cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = nn.DataParallel(model.cuda(), device_ids=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c7c421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "# Max Batch Size supported by GPU\n",
    "batch_size = 8\n",
    "\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_dataset_for_reviews[\"train\"]) // batch_size \n",
    "\n",
    "model_name = 'outputmodel/review_generation/' + extraction_method + '/' + model_output_name\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\" # disable wandb\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir= workdir + model_name,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=weight_decay,\n",
    "    save_strategy='epoch',\n",
    "    # include_inputs_for_metrics=True, # added for eval to access decision_labels\n",
    "    label_names=['decision_label', 'confidence', 'logCitNum', 'rating', 'ner_labels'], # needed to feed decision_label into training loop\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True, \n",
    "    generation_max_length=max_review_length, \n",
    "    logging_steps=logging_steps,\n",
    "    report_to=None \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c163bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb566f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del net\n",
    "# del cuda_model\n",
    "# del trainer\n",
    "# \n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6e07d22-86a9-4485-9627-a692680690f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'labels', 'tokens', 'tk_labels', 'title', 'decision', 'abstract', 'intro', 'conference', 'review', 'decision_label', 'intro_len', 'abstract_len', 'review_len', 'ce_extract', 'ce_extract_len', 'hybrid', 'hybrid_len', 'pid', 'rid', 'uid', 'confidence_str', 'rating_str', 'paper_len', 'conclusion', 'conclusion_len', 'url', 'emails', 'source', 'authors', 'confidence', 'rating', 'decision_binary', 'review_no_whitespace', 'CitNum', 'logCitNum', 'tk_label_nums', '__index_level_0__', 'input_ids', 'attention_mask', 'ner_labels'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'labels', 'tokens', 'tk_labels', 'title', 'decision', 'abstract', 'intro', 'conference', 'review', 'decision_label', 'intro_len', 'abstract_len', 'review_len', 'ce_extract', 'ce_extract_len', 'hybrid', 'hybrid_len', 'pid', 'rid', 'uid', 'confidence_str', 'rating_str', 'paper_len', 'conclusion', 'conclusion_len', 'url', 'emails', 'source', 'authors', 'confidence', 'rating', 'decision_binary', 'review_no_whitespace', 'CitNum', 'logCitNum', 'tk_label_nums', '__index_level_0__', 'input_ids', 'attention_mask', 'ner_labels'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_for_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02dd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Review Loss: 3.6264796257019043\n",
      "NER Loss: 1.1326136589050293\n",
      "8\n",
      "Review Loss: 3.9311184883117676\n",
      "NER Loss: 1.4954568147659302\n",
      "8\n",
      "Review Loss: 3.177537202835083\n",
      "NER Loss: 1.116485834121704\n",
      "8\n",
      "Review Loss: 3.500415325164795\n",
      "NER Loss: 0.7443220019340515\n",
      "8\n",
      "Review Loss: 4.109851837158203\n",
      "NER Loss: 1.1411259174346924\n",
      "8\n",
      "Review Loss: 4.200204372406006\n",
      "NER Loss: 1.7574920654296875\n",
      "8\n",
      "Review Loss: 2.9196300506591797\n",
      "NER Loss: 1.6662766933441162\n",
      "8\n",
      "Review Loss: 3.2835657596588135\n",
      "NER Loss: 1.189716100692749\n",
      "8\n",
      "Review Loss: 2.9775075912475586\n",
      "NER Loss: 1.2557439804077148\n",
      "8\n",
      "Review Loss: 3.8763813972473145\n",
      "NER Loss: 1.1853622198104858\n",
      "8\n",
      "Review Loss: 3.3122775554656982\n",
      "NER Loss: 1.5808745622634888\n",
      "8\n",
      "Review Loss: 3.5920569896698\n",
      "NER Loss: 1.3825093507766724\n",
      "8\n",
      "Review Loss: 1.9725956916809082\n",
      "NER Loss: 1.4021357297897339\n",
      "8\n",
      "Review Loss: 3.3412394523620605\n",
      "NER Loss: 1.2507399320602417\n",
      "8\n",
      "Review Loss: 3.603506565093994\n",
      "NER Loss: 1.101052165031433\n",
      "8\n",
      "Review Loss: 3.5141305923461914\n",
      "NER Loss: 0.9877867102622986\n",
      "8\n",
      "Review Loss: 3.2121315002441406\n",
      "NER Loss: 1.04936945438385\n",
      "8\n",
      "Review Loss: 3.1968142986297607\n",
      "NER Loss: 1.0630083084106445\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# Set Up Model Training\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_dataset_for_reviews[\"train\"],\n",
    "    eval_dataset=tokenized_dataset_for_reviews[\"test\"],\n",
    "    data_collator=DataCollatorForSeq2Seq(bart_tokenizer, model=model, max_length=max_review_length),\n",
    "    tokenizer=bart_tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train Model on Tokenized DataSet\n",
    "trainer.train()\n",
    "\n",
    "# Save Model\n",
    "# save_path = 'outputmodel/review_generation/hybrid/' + model_output_name\n",
    "# trainer.save_model(workdir + save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafddda3",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c377302-085e-4132-9fb8-d08442557f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_name = 'review_ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e2b7499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./outputmodel/review_generation/hybrid/citations_and_metadata'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Model\n",
    "save_path = workdir + 'outputmodel/' + model_output_name \n",
    "# trainer.save_model(workdir + save_path)\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f55fdc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
    "model = ExtendedBart.from_pretrained(save_path)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed8bea3b-317d-44b1-af01-19b59c6d2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ner_accuracy(ner_pred, ner_target):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(len(ner_target)):\n",
    "        if ner_target[i] == -100:\n",
    "            continue\n",
    "        total += 1\n",
    "        correct += (ner_target[i] == ner_pred[i])\n",
    "    \n",
    "    return correct, total, correct / float(total)\n",
    "\n",
    "def compute_all_ner_accuracy(ner_preds, ner_targets):\n",
    "    eval_total, eval_correct = 0, 0\n",
    "\n",
    "    for i in range(len(ner_preds)):\n",
    "        correct, total, ratio = compute_ner_accuracy(ner_preds[i], ner_targets[i])\n",
    "\n",
    "        eval_total += total\n",
    "        eval_correct += correct\n",
    "    \n",
    "    # print(eval_correct)\n",
    "    # print(eval_total)\n",
    "    return (eval_correct / float(eval_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0eb74d6d-f008-4921-aae0-be2c9819d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del input_ids\n",
    "# del outputs\n",
    "# del attention_mask\n",
    "# del labels\n",
    "# del decision_label\n",
    "# del ner_labels\n",
    "# del ner_pred\n",
    "# del target\n",
    "# del logCitNum\n",
    "# del confidence\n",
    "# del rating\n",
    "# del logCitNum_pred\n",
    "# del confidence_pred\n",
    "# del rating_pred\n",
    "\n",
    "# del decision_preds\n",
    "# del decision_targets\n",
    "\n",
    "# del confidence_preds\n",
    "# del confidence_targets\n",
    "\n",
    "# del logCitNum_preds\n",
    "# del logCitNum_targets\n",
    "\n",
    "# del rating_preds\n",
    "# del rating_targets\n",
    "\n",
    "# del ner_preds\n",
    "# del ner_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "\n",
    "decision_preds = []\n",
    "decision_targets = []\n",
    "\n",
    "confidence_preds = []\n",
    "confidence_targets = []\n",
    "\n",
    "logCitNum_preds = []\n",
    "logCitNum_targets = []\n",
    "\n",
    "rating_preds = []\n",
    "rating_targets = []\n",
    "\n",
    "ner_preds = []\n",
    "ner_targets = []\n",
    "\n",
    "m = nn.Sigmoid()\n",
    "for data in tokenized_dataset_for_reviews['test']:\n",
    "    input_ids = torch.IntTensor([data[\"input_ids\"]]).to(device)\n",
    "    attention_mask = torch.IntTensor([data[\"attention_mask\"]]).to(device)\n",
    "    labels = torch.LongTensor([data[\"labels\"]]).to(device)\n",
    "\n",
    "    decision_label, confidence, logCitNum, rating, ner_labels = None, None, None, None, None\n",
    "\n",
    "    if train_citation: \n",
    "        logCitNum = torch.FloatTensor([data[\"logCitNum\"]]).to(device)\n",
    "    \n",
    "    if train_decision:\n",
    "        decision_label = torch.FloatTensor([data[\"decision_label\"]]).to(device)\n",
    "\n",
    "    if train_confidence:\n",
    "        confidence = torch.FloatTensor([data[\"confidence\"]]).to(device)\n",
    "\n",
    "    if train_rating:\n",
    "        rating = torch.FloatTensor([data[\"rating\"]]).to(device)\n",
    "\n",
    "    if train_aspect_score:\n",
    "        ner_labels = torch.LongTensor([data[\"ner_labels\"]]).to(device)\n",
    "\n",
    "    outputs = model.forward(input_ids=input_ids, \n",
    "                          attention_mask=attention_mask, \n",
    "                          labels=labels, \n",
    "                          decision_label=decision_label, # new\n",
    "                          confidence=confidence, # new\n",
    "                          logCitNum=logCitNum, # new\n",
    "                          rating=rating, # new\n",
    "                          ner_labels=ner_labels # new, unused?\n",
    "                          )\n",
    "\n",
    "    if train_citation: \n",
    "        logCitNum_pred = outputs[\"logCitNum_pred\"].to(device)\n",
    "        pred = logCitNum_pred.cpu().detach().numpy()[0]\n",
    "        logCitNum_preds.append(pred)\n",
    "        target = logCitNum.cpu().detach().numpy()[0]\n",
    "        logCitNum_targets.append(target)\n",
    "\n",
    "    if train_decision:\n",
    "        decision_pred = outputs[\"decision_pred\"].to(device)\n",
    "        decision_pred = torch.sigmoid(decision_pred)\n",
    "        pred = decision_pred.cpu().detach().numpy()[0]\n",
    "        decision_preds.append(pred)\n",
    "        target = decision_label.cpu().detach().numpy()[0]\n",
    "        decision_targets.append(target)\n",
    "\n",
    "    if train_confidence:\n",
    "        confidence_pred = outputs[\"confidence_pred\"].to(device)\n",
    "        pred = confidence_pred.cpu().detach().numpy()[0]\n",
    "        confidence_preds.append(pred)\n",
    "        target = confidence.cpu().detach().numpy()[0]\n",
    "        confidence_targets.append(target)\n",
    "\n",
    "    if train_rating:\n",
    "        rating_pred = outputs[\"rating_pred\"].to(device)\n",
    "        pred = rating_pred.cpu().detach().numpy()[0]\n",
    "        rating_preds.append(pred)\n",
    "        target = rating.cpu().detach().numpy()[0]\n",
    "        rating_targets.append(target)\n",
    "    \n",
    "    if train_aspect_score:\n",
    "        ner_pred = outputs['aspect_pred'].to(device)\n",
    "        ner_pred = ner_pred.cpu().detach()\n",
    "        ner_pred_label = ner_pred.argmax(axis=1)\n",
    "        ner_preds.extend(ner_pred_label)\n",
    "\n",
    "        ner_target = ner_labels.cpu().detach().numpy()\n",
    "        ner_targets.extend(ner_target)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39340873-006c-4113-9898-007e7ff84621",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_citation=True\n",
    "train_decision=True\n",
    "train_confidence=False\n",
    "train_rating=True\n",
    "train_review=True\n",
    "train_aspect_score=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48f7b8-339b-432a-9399-9cb44faf37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.array(decision_targets) != np.round(np.array(decision_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e04505-6656-4438-8877-bcf647a83ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rating_targets), np.std(confidence_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe8338-552b-4804-80a1-c2a60f2fecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(logCitNum_targets), np.std(logCitNum_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11a3f07e-25d5-4be7-af4b-2f1a74fcf459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogCitation MSE:1.4867797\n",
      "Decision AUC:0.5291560102301791\n",
      "Confidence MSE:0.6943817\n",
      "Rating MSE:0.896362\n"
     ]
    }
   ],
   "source": [
    "if train_citation: \n",
    "    print(\"LogCitation MSE:\" + str(mean_squared_error(logCitNum_preds, logCitNum_targets))) # new\n",
    "\n",
    "if train_decision:\n",
    "    print(\"Decision AUC:\" + str(roc_auc_score(decision_targets, decision_preds))) # new\n",
    "\n",
    "if train_confidence:\n",
    "    print(\"Confidence MSE:\" + str(mean_squared_error(confidence_preds, confidence_targets))) # new \n",
    "\n",
    "if train_rating:\n",
    "    print(\"Rating MSE:\" + str(mean_squared_error(rating_preds, rating_targets))) # new\n",
    "    \n",
    "if train_aspect_score:\n",
    "    print(\"NER F1 Score:\" + str(compute_all_ner_accuracy(ner_preds, ner_targets))) # new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57d6ac-b4a5-4590-8668-c1bebbb18d7e",
   "metadata": {},
   "source": [
    "# Section Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971dd6cc-556d-41de-97e4-24c78003c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "section = 'clarity'\n",
    "section_model_output_name = model_output_name + '_section'\n",
    "\n",
    "section_token_col = \"section\" + \"_tokens\"\n",
    "section_token_labels_col = \"section\" + '_tk_labels' \n",
    "section_token_label_nums_col = \"section\" + '_tk_label_nums'\n",
    "\n",
    "section_review_length = 256 if section == 'summary' else 128\n",
    "section_inp_filename = 'all_pp_df_with_as_breakdowns.csv'\n",
    "\n",
    "sample_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5750c-2d03-421d-b056-9d7bfadaa0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_section_df(df, section):\n",
    "    def concat_columns(row, column_sfx):\n",
    "        return row[f'{section}_positive_{column_sfx}'] + row[f'{section}_negative_{column_sfx}']\n",
    "    \n",
    "    if section == 'summary':\n",
    "        filt_df = df[df[f'{section}_length'] > 0]\n",
    "        filt_df[f'{section}_tokens'] = filt_df[f'{section}_tokens'].apply(eval)\n",
    "        filt_df[section_token_col] = filt_df[f'{section}_tokens']\n",
    "    else:\n",
    "        filt_df = df[(df[f'{section}_positive_length'] > 0) |\n",
    "                     (df[f'{section}_negative_length'] > 0)\n",
    "                    ]\n",
    "    \n",
    "        filt_df[f'{section}_positive_tokens'] = filt_df[f'{section}_positive_tokens'].apply(eval)\n",
    "        filt_df[f'{section}_negative_tokens'] = filt_df[f'{section}_negative_tokens'].apply(eval)\n",
    "        filt_df[section_token_col] = filt_df.apply(lambda row: concat_columns(row, 'tokens'), axis=1)\n",
    "#     filt_df[section_token_labels_col] = filt_df.apply(lambda row: concat_columns(row, 'tk_labels'), axis=1)\n",
    "\n",
    "    return filt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b758c7-d5ea-4fa7-8530-9af33269b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_df = pd.read_csv(workdir + section_inp_filename)\n",
    "all_input_df = preprocess_section_df(all_input_df, section)\n",
    "all_input_df = all_input_df[~all_input_df['ce_extract'].isna()]\n",
    "\n",
    "if sample_size:\n",
    "    sample_df = all_input_df.sample(sample_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aecfba-ebc5-40e8-9b12-97e6de3704cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = Dataset.from_pandas(sample_df if sample_size else all_input_df)\n",
    "input_dataset_dict = input_dataset.train_test_split(test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ef927-3793-4519-9d8b-cfe8711f29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function_for_section_review_task(paper_json, extraction_method='hybrid', device=device):\n",
    "\n",
    "    if extraction_method == 'intro':\n",
    "        input_text = paper_json['intro']\n",
    "    elif extraction_method == 'ce_extract':\n",
    "        input_text = paper_json['ce_extract']\n",
    "    elif extraction_method == 'hybrid':\n",
    "        input_text = paper_json['abstract'] + paper_json['ce_extract']\n",
    "\n",
    "    model_inputs = bart_tokenizer(\n",
    "        input_text,\n",
    "        max_length=max_paper_extract_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    labels = bart_tokenizer(\n",
    "        paper_json[section_token_col], is_split_into_words=True,\n",
    "        max_length=section_review_length, truncation=True, padding='max_length'\n",
    "    )\n",
    "    model_inputs[\"labels\"] = torch.tensor(labels[\"input_ids\"]).to(device)\n",
    "    model_inputs['input_ids'] = torch.tensor(model_inputs['input_ids']).to(device)\n",
    "    # print(len(model_inputs['labels']))\n",
    "    # print(len(paper_json['text']))\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "tokenized_section_dataset_for_reviews = input_dataset_dict.map(lambda s: \n",
    "   preprocess_function_for_section_review_task(s, extraction_method=extraction_method, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1008ea-10c3-4d2e-94fd-c95798fccaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa76f2-4d7b-4f85-9a90-4c5ee533ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "# del net\n",
    "# del cuda_model\n",
    "del trainer\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5107b5-8559-4428-944c-15dc9353f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extended_cfg = ExtendedBartConfig()\n",
    "bart_config = BartConfig()\n",
    "model = ExtendedBart(config=bart_config).from_pretrained(\"facebook/bart-large-cnn\",  #pre_trained_model_checkpoint\n",
    "                                                         max_length=max_review_length, \n",
    "                                                         min_length=min_text_length,\n",
    "                                                         task_specific_params=summarization_params)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4c55ec-1f02-41f7-8630-a9e6b9e7ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_section_dataset_for_reviews[\"train\"],\n",
    "    eval_dataset=tokenized_section_dataset_for_reviews[\"test\"],\n",
    "    data_collator=DataCollatorForSeq2Seq(bart_tokenizer, model=model, max_length=max_review_length),\n",
    "    tokenizer=bart_tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# New code - wrap collator in a dictionary\n",
    "# old_collator = trainer.data_collator\n",
    "# trainer.data_collator = lambda data: dict(old_collator(data))\n",
    "# End new code\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "# Train Model on Tokenized DataSet\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50f979-9f26-4185-9699-f813b810b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f'outputmodel/review_generation/hybrid/{section}_200_section_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1884f67-0381-43fb-8490-f5f2cdc7d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "trainer.save_model(workdir + save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47234213",
   "metadata": {},
   "source": [
    "## Generate Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870e410-8eae-4b94-9096-47b0bbd1b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_outputs_df = pd.read_csv(workdir + 'all_pp_df_with_as_breakdowns.csv')\n",
    "\n",
    "sample_outputs_df = sample_outputs_df[\n",
    "    ((sample_outputs_df['clarity_positive_length'] > 0) | (sample_outputs_df['clarity_negative_length'] > 0)) & \n",
    "    (sample_outputs_df['summary_length'] > 0) & \n",
    "    ((sample_outputs_df['substance_positive_length'] > 0) | (sample_outputs_df['substance_negative_length'] > 0)) &\n",
    "    ((sample_outputs_df['soundness_positive_length'] > 0) | (sample_outputs_df['soundness_negative_length'] > 0)) &\n",
    "    ((sample_outputs_df['originality_positive_length'] > 0) | (sample_outputs_df['originality_negative_length'] > 0))\n",
    "\n",
    "]\n",
    "\n",
    "seed = 282\n",
    "\n",
    "ds_df = sample_outputs_df.sample(5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5249622-c811-4c2d-9ccf-e8f30c95b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eabe88-9460-4687-88d7-22bbadb4e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "entries = []\n",
    "for path in model_paths:\n",
    "      print(path)\n",
    "\n",
    "# section = 'summary'\n",
    "  \n",
    "    tokenizer = AutoTokenizer.from_pretrained(workdir + path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(workdir + path)\n",
    "\n",
    "    for i, row in ds_df.iterrows():\n",
    "        print(i)\n",
    "        id = row['id']\n",
    "        extraction_txt = row[extraction_method]\n",
    "\n",
    "        inputs = tokenizer(extraction_txt, return_tensors=\"pt\", truncation=True).input_ids\n",
    "        outputs = model.generate(inputs)\n",
    "\n",
    "        decoded_output = \"\"\n",
    "        for output in outputs:\n",
    "            decoded_output += tokenizer.decode(output, skip_special_tokens=True)\n",
    "\n",
    "        entry = {\n",
    "            'id': id,\n",
    "            'extraction_method': extraction_method,\n",
    "            'extraction_text': extraction_txt,\n",
    "            'model_name': ''.join(path.split('/')[3:]),\n",
    "            'title': row['title'],\n",
    "            'abstract': row['abstract'],\n",
    "            'review': row['review'],\n",
    "            'model_review_output': decoded_output,\n",
    "            'model_output_length': len(decoded_output.split(' '))\n",
    "        }\n",
    "\n",
    "        entries.append(entry)\n",
    "        print(len(entries))\n",
    "  \n",
    "    # df_map[section] = pd.DataFrame(entries)\n",
    "\n",
    "    del model\n",
    "    del tokenizer\n",
    "    gc.collect()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "output_df = pd.DataFrame(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b4798-67e8-4abb-b5e6-3fb9cfae7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b582bc1d-78df-46d1-9999-7440d52b3ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('./sample_section_outputs_v4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a30377-3e41-422e-a49d-7484d5a86769",
   "metadata": {},
   "source": [
    "## Generate Text for One Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4142f95-4b90-435a-924c-7af5a54192e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = tokenized_dataset_for_reviews['train'][0][extraction_method]\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(workdir + model_name)\n",
    "inputs = bart_tokenizer(txt, return_tensors=\"pt\", truncation=True).input_ids\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(workdir + local_checkpoint)\n",
    "outputs = model.generate(inputs)\n",
    "\n",
    "decoded_output = \"\"\n",
    "for output in outputs:\n",
    "    decoded_output += tokenizer.decode(output, skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
