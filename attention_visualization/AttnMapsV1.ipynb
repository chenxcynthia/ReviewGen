{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4036e4",
   "metadata": {
    "id": "6b4036e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/cynthiachen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307aa482",
   "metadata": {
    "id": "307aa482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.13.0)\n",
      "Requirement already satisfied: packaging in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: xxhash in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: pandas in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.3)\n",
      "Requirement already satisfied: aiohttp in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: dill<0.3.7 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: filelock in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (0.1.97)\n",
      "Requirement already satisfied: rouge_score in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: numpy in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from rouge_score) (1.21.5)\n",
      "Requirement already satisfied: nltk in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: absl-py in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from nltk->rouge_score) (2022.3.15)\n",
      "Requirement already satisfied: click in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from nltk->rouge_score) (4.64.0)\n",
      "Requirement already satisfied: wandb in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (0.13.11)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (4.1.1)\n",
      "Requirement already satisfied: setuptools in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (61.2.0)\n",
      "Requirement already satisfied: setproctitle in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (3.1.31)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (4.21.12)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: PyYAML in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: bert-score in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (0.3.13)\n",
      "Requirement already satisfied: numpy in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (1.21.5)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (1.4.3)\n",
      "Requirement already satisfied: torch>=1.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (1.12.1)\n",
      "Requirement already satisfied: requests in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (21.3)\n",
      "Requirement already satisfied: matplotlib in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (3.5.1)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (4.64.0)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (4.26.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->bert-score) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (4.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.13.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (2022.3.15)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->bert-score) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->bert-score) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->bert-score) (9.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->bert-score) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->bert-score) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->bert-score) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->bert-score) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: evaluate in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from evaluate) (2.9.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from evaluate) (4.64.0)\n",
      "Requirement already satisfied: pandas in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from evaluate) (1.4.3)\n",
      "Requirement already satisfied: packaging in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: dill in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: multiprocess in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from evaluate) (2022.2.0)\n",
      "Requirement already satisfied: xxhash in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from evaluate) (1.21.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from evaluate) (0.13.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from evaluate) (2.27.1)\n",
      "Requirement already satisfied: aiohttp in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.8.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.1.1)\n",
      "Requirement already satisfied: filelock in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from packaging->evaluate) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from pandas->evaluate) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (4.26.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.13.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: filelock in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.26.1\n",
      "    Uninstalling transformers-4.26.1:\n",
      "      Successfully uninstalled transformers-4.26.1\n",
      "Successfully installed transformers-4.27.4\n",
      "Requirement already satisfied: bert-score in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (1.12.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (1.4.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (4.27.4)\n",
      "Requirement already satisfied: requests in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (21.3)\n",
      "Requirement already satisfied: numpy in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (1.21.5)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (4.64.0)\n",
      "Requirement already satisfied: matplotlib in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bert-score) (3.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->bert-score) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2021.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (4.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.12.1)\n",
      "Requirement already satisfied: filelock in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (2022.3.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.13.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->bert-score) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->bert-score) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->bert-score) (1.3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->bert-score) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->bert-score) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->bert-score) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->bert-score) (2.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: bertviz in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: tqdm in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bertviz) (4.64.0)\n",
      "Requirement already satisfied: boto3 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bertviz) (1.21.32)\n",
      "Requirement already satisfied: sentencepiece in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bertviz) (0.1.97)\n",
      "Requirement already satisfied: regex in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bertviz) (2022.3.15)\n",
      "Requirement already satisfied: transformers>=2.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bertviz) (4.27.4)\n",
      "Requirement already satisfied: requests in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bertviz) (2.27.1)\n",
      "Requirement already satisfied: torch>=1.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from bertviz) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.0->bertviz) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=2.0->bertviz) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=2.0->bertviz) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=2.0->bertviz) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=2.0->bertviz) (0.13.0)\n",
      "Requirement already satisfied: filelock in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=2.0->bertviz) (3.6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from transformers>=2.0->bertviz) (0.12.1)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.32 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from boto3->bertviz) (1.24.32)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from boto3->bertviz) (0.5.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from boto3->bertviz) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->bertviz) (1.26.14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->bertviz) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->bertviz) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from requests->bertviz) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from botocore<1.25.0,>=1.24.32->boto3->bertviz) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers>=2.0->bertviz) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/cynthiachen/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.32->boto3->bertviz) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "\n",
    "# ! pip install datasets\n",
    "# ! pip install sentencepiece\n",
    "# ! pip install rouge_score\n",
    "# ! pip install wandb\n",
    "# ! pip install bert-score\n",
    "# ! pip install evaluate\n",
    "# ! pip install transformers -U\n",
    "# ! pip install bert-score\n",
    "# ! pip install bertviz\n",
    "\n",
    "from transformers import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V4pM0TjpDB9Z",
   "metadata": {
    "id": "V4pM0TjpDB9Z"
   },
   "outputs": [],
   "source": [
    "# # Connect code to Google Drive (if necessary)\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# gdrive_dir = '/content/drive/MyDrive/CS 282 Project/Checkpoint 2/cs282-project/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a02a70f",
   "metadata": {
    "id": "1a02a70f"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "GYk-R9PNZhcb",
   "metadata": {
    "id": "GYk-R9PNZhcb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdrive_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m workdir \u001b[38;5;241m=\u001b[39m \u001b[43mgdrive_dir\u001b[49m\n\u001b[1;32m      3\u001b[0m input_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpanded_all_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Full DataSet Size is 15000 (review, paper), but due to GPU cost + time constraints, we use a sub-sample of 5000 reviews\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gdrive_dir' is not defined"
     ]
    }
   ],
   "source": [
    "workdir = gdrive_dir\n",
    "\n",
    "input_filename = 'expanded_all_data.json'\n",
    "\n",
    "# Full DataSet Size is 15000 (review, paper), but due to GPU cost + time constraints, we use a sub-sample of 5000 reviews\n",
    "sample_size = 25 \n",
    "\n",
    "seed = 100\n",
    "\n",
    "# Specify Extraction Method used to Generate Training Text from Papers\n",
    "# Either: (intro, ce_extract, hybrid)\n",
    "extraction_method = 'hybrid'\n",
    "\n",
    "# Maximum Token Length of Paper Extracts Used To Train Model\n",
    "max_paper_extract_length = 1024 # 1024 is the max input size of a BART model\n",
    "max_review_length = 1024\n",
    "min_text_length = 100\n",
    "\n",
    "# Pre-Trained Hugging Face Seq2Seq Transformers Model\n",
    "pre_trained_model_checkpoint = \"facebook/bart-large-cnn\"\n",
    "\n",
    "# Summarization Task Configuration\n",
    "summarization_params = {\n",
    "    \"summarization\": {\n",
    "        \"early_stopping\": True,\n",
    "        \"length_penalty\": 2.0, # BART (favor longer sequences)\n",
    "        \"max_length\": max_review_length,\n",
    "        \"min_length\": min_text_length,\n",
    "        \"no_repeat_ngram_size\": 3, # BART default\n",
    "        \"num_beams\": 4 # BART default\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d9b322",
   "metadata": {
    "id": "c4d9b322"
   },
   "source": [
    "## Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062c46a",
   "metadata": {
    "id": "e062c46a"
   },
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets, DatasetDict, Dataset, load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load input data (post-extraction and pre-processing to downsample paper text)\n",
    "all_input_df = pd.read_json(workdir + input_filename, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vkc3WgSKgpId",
   "metadata": {
    "id": "Vkc3WgSKgpId"
   },
   "source": [
    "Load Tokenizer For Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JNFueJSFgwhC",
   "metadata": {
    "id": "JNFueJSFgwhC"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load Tokenizer used with the corresponding pre-trained mode\n",
    "tokenizer = AutoTokenizer.from_pretrained(pre_trained_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sa5oYS5lhPe_",
   "metadata": {
    "id": "Sa5oYS5lhPe_"
   },
   "outputs": [],
   "source": [
    "# Filter on token length [not currently used because it decreases the available \n",
    "# dataset size for the CE_extraction method]\n",
    "def filter_on_token_length(df, tokenizer, text_col, text_min=min_text_length, \n",
    "                           text_max=max_paper_extract_length, review_min=min_text_length, \n",
    "                           review_max=max_review_length):\n",
    "    \n",
    "    def test_length_constraints(txt, tokenizer, mn_length, mx_length):\n",
    "        tokenized_txt = tokenizer(txt, max_length=None, truncation=False)\n",
    "        num_tokens = len(tokenized_txt['input_ids'])\n",
    "\n",
    "        return (num_tokens >= mn_length) and (num_tokens <= mx_length)\n",
    "      \n",
    "    return df[\n",
    "              (df[text_col].apply(lambda s: test_length_constraints(s, tokenizer, text_min, text_max))) &\n",
    "              (df['review'].apply(lambda s: test_length_constraints(s, tokenizer, review_min, review_max)))\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KuNhPSLohOVZ",
   "metadata": {
    "id": "KuNhPSLohOVZ"
   },
   "outputs": [],
   "source": [
    "filt_input_df = all_input_df # [not currently used] filter_on_token_length(df_exp, tokenizer, extraction_method)\n",
    "if sample_size:\n",
    "    sample_df = filt_input_df.sample(sample_size, random_state=seed)\n",
    "input_dataset = Dataset.from_pandas(sample_df if sample_size else filt_input_df)\n",
    "input_dataset_dict = input_dataset.train_test_split(test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d94fb72",
   "metadata": {
    "id": "7d94fb72"
   },
   "outputs": [],
   "source": [
    "input_dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4cddda",
   "metadata": {
    "id": "6b4cddda"
   },
   "source": [
    "## Tokenize DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jPFus8qeo4us",
   "metadata": {
    "id": "jPFus8qeo4us"
   },
   "outputs": [],
   "source": [
    "def preprocess_function_for_review_task(paper_json, extraction_method='intro'):\n",
    "    if extraction_method == 'intro':\n",
    "        input_text = paper_json['intro']\n",
    "    elif extraction_method == 'ce_extract':\n",
    "        input_text = paper_json['ce_extract']\n",
    "    elif extraction_method == 'hybrid':\n",
    "        input_text = paper_json['ce_extract'] + paper_json['abstract']\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        input_text,\n",
    "        max_length=max_paper_extract_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        text_target=paper_json[\"review\"], \n",
    "        max_length=max_review_length, truncation=True\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    # print(len(model_inputs['labels']))\n",
    "    # print(len(paper_json['text']))\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eI0JbZ49SoKU",
   "metadata": {
    "id": "eI0JbZ49SoKU"
   },
   "outputs": [],
   "source": [
    "tokenized_dataset_for_reviews = input_dataset_dict.map(lambda s: preprocess_function_for_review_task(s, extraction_method=extraction_method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U7CGDY89bkej",
   "metadata": {
    "id": "U7CGDY89bkej"
   },
   "outputs": [],
   "source": [
    "tokenized_dataset_for_reviews # validate train / test sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sggu9SA5PDsl",
   "metadata": {
    "id": "sggu9SA5PDsl"
   },
   "outputs": [],
   "source": [
    "len(tokenized_dataset_for_reviews['train'][0]['input_ids']) # validate that tokenizer creates encoding of expected token length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "os3wpntP4vRI",
   "metadata": {
    "id": "os3wpntP4vRI"
   },
   "source": [
    "Note that the token length exceeds 1024, which is the maximum input size for BART, so some of the input will be truncated. We were surprised that this was teh case for the cross-entropy inputs, since we used the authors default configuration for downsampling the paper to an input text and the authors state that they use BART for their Seq2Seq models. It's possible that they are using another tokenizer.\n",
    "\n",
    "In any case, due to time constraints (of re-running cross-entropy extraction and/or determining a different tokenizer/vocabulary file to use), we truncate inputs for now and leave further investigation to the next steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33hubwPfLK4L",
   "metadata": {
    "id": "33hubwPfLK4L"
   },
   "source": [
    "# Create Attention Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wm_7JXPnb_3n",
   "metadata": {
    "id": "Wm_7JXPnb_3n"
   },
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from bertviz import model_view\n",
    "from bertviz import head_view\n",
    "\n",
    "# Example: https://github.com/jessevig/bertviz/blob/master/notebooks/model_view_encoder_decoder.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62-8IWf7LQmQ",
   "metadata": {
    "id": "62-8IWf7LQmQ"
   },
   "source": [
    "Load pre-trained model + tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YDFJRCwcLMyc",
   "metadata": {
    "id": "YDFJRCwcLMyc"
   },
   "outputs": [],
   "source": [
    "local_checkpoint = workdir + 'outputmodel/review_generation/' + extraction_method\n",
    "\n",
    "# Load Tokenizer used with the corresponding pre-trained mode\n",
    "tokenizer = AutoTokenizer.from_pretrained(pre_trained_model_checkpoint)\n",
    "\n",
    "# Load Pre-TrainedModel from BART\n",
    "if local_checkpoint:\n",
    "    pre_trained_model_checkpoint = local_checkpoint\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(pre_trained_model_checkpoint, \n",
    "                                                     max_length=max_review_length, # use max_new_tokens instead?\n",
    "                                                     min_length=min_text_length,\n",
    "                                                     task_specific_params=summarization_params,\n",
    "                                                     output_attentions=True)\n",
    "\n",
    "# model_name = 'outputmodel/review_generation/' + extraction_method\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(workdir + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZkmlIZ3kLYB6",
   "metadata": {
    "id": "ZkmlIZ3kLYB6"
   },
   "source": [
    "Use BertViz package to create attention maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WwM2eHgBV1fI",
   "metadata": {
    "id": "WwM2eHgBV1fI"
   },
   "outputs": [],
   "source": [
    "txt = tokenized_dataset_for_reviews['train'][0][extraction_method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NmtvaWuihDWK",
   "metadata": {
    "id": "NmtvaWuihDWK"
   },
   "outputs": [],
   "source": [
    "# Select data\n",
    "\n",
    "# get encoded input vectors\n",
    "inputs = tokenizer(txt[0:50], return_tensors=\"pt\", truncation=True)\n",
    "encoder_input_ids = inputs.input_ids\n",
    "\n",
    "# generate model outputs\n",
    "model_outputs = model.generate(encoder_input_ids)\n",
    "decoded_output = \"\"\n",
    "for output in model_outputs:\n",
    "  decoded_output += tokenizer.decode(output, skip_special_tokens=True)\n",
    "\n",
    "# create ids of encoded input vectors\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    decoder_input_ids = tokenizer(decoded_output, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "haBYPbnxlamc",
   "metadata": {
    "id": "haBYPbnxlamc"
   },
   "outputs": [],
   "source": [
    "input_text = txt[0:50]\n",
    "output_text = decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gT878S2gm_ZG",
   "metadata": {
    "id": "gT878S2gm_ZG"
   },
   "outputs": [],
   "source": [
    "outputs = model(input_ids=encoder_input_ids, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "encoder_text = tokenizer.convert_ids_to_tokens(encoder_input_ids[0])\n",
    "decoder_text = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U2Pee1CIL9EQ",
   "metadata": {
    "id": "U2Pee1CIL9EQ"
   },
   "outputs": [],
   "source": [
    "# Display the visualization using either head_view or model_view\n",
    "head_view(\n",
    "    encoder_attention=outputs.encoder_attentions,\n",
    "    decoder_attention=outputs.decoder_attentions,\n",
    "    cross_attention=outputs.cross_attentions,\n",
    "    encoder_tokens=encoder_text,\n",
    "    decoder_tokens=decoder_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L3mUND_clVWi",
   "metadata": {
    "id": "L3mUND_clVWi"
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel, utils\n",
    "# from bertviz import model_view\n",
    "\n",
    "# utils.logging.set_verbosity_error()  # Remove line to see warnings\n",
    "\n",
    "# # Initialize tokenizer and model. Be sure to set output_attentions=True.\n",
    "# # Load BART fine-tuned for summarization on CNN/Daily Mail dataset\n",
    "# model_name = \"facebook/bart-large-cnn\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModel.from_pretrained(model_name, output_attentions=True) # LOOK AT THIS!!!!\n",
    "\n",
    "# # get encoded input vectors\n",
    "# encoder_input_ids = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
    "\n",
    "# # create ids of encoded input vectors\n",
    "# decoder_input_ids = tokenizer(output_text, return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
    "\n",
    "# outputs = model(input_ids=encoder_input_ids, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "# encoder_text = tokenizer.convert_ids_to_tokens(encoder_input_ids[0])\n",
    "# decoder_text = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])\n",
    "\n",
    "# model_view(\n",
    "#     encoder_attention=outputs.encoder_attentions,\n",
    "#     decoder_attention=outputs.decoder_attentions,\n",
    "#     cross_attention=outputs.cross_attentions,\n",
    "#     encoder_tokens= encoder_text,\n",
    "#     decoder_tokens=decoder_text\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9i1ayD6yfpyy",
   "metadata": {
    "id": "9i1ayD6yfpyy"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils\n",
    "from bertviz import model_view\n",
    "\n",
    "utils.logging.set_verbosity_error()  # Remove line to see warnings\n",
    "\n",
    "# Initialize tokenizer and model. Be sure to set output_attentions=True.\n",
    "# Load BART fine-tuned for summarization on CNN/Daily Mail dataset\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, output_attentions=True) # LOOK AT THIS!!!!\n",
    "\n",
    "# get encoded input vectors\n",
    "encoder_input_ids = tokenizer(\"The House Budget Committee voted Saturday to pass a $3.5 trillion spending bill\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
    "\n",
    "# create ids of encoded input vectors\n",
    "decoder_input_ids = tokenizer(\"The House Budget Committee passed a spending bill.\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
    "\n",
    "outputs = model(input_ids=encoder_input_ids, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "encoder_text = tokenizer.convert_ids_to_tokens(encoder_input_ids[0])\n",
    "decoder_text = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])\n",
    "\n",
    "model_view(\n",
    "    encoder_attention=outputs.encoder_attentions,\n",
    "    decoder_attention=outputs.decoder_attentions,\n",
    "    cross_attention=outputs.cross_attentions,\n",
    "    encoder_tokens= encoder_text,\n",
    "    decoder_tokens=decoder_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oVZAGDvyjXp8",
   "metadata": {
    "id": "oVZAGDvyjXp8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "research23",
   "language": "python",
   "name": "research23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
