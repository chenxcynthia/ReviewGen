{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b4036e4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import importlib\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "id": "6b4036e4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tdP3ef360_Y"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ],
      "id": "1tdP3ef360_Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "307aa482"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "\n",
        "! pip install datasets\n",
        "! pip install sentencepiece\n",
        "! pip install rouge_score\n",
        "! pip install wandb\n",
        "! pip install bert-score\n",
        "! pip install evaluate\n",
        "! pip install transformers -U\n",
        "! pip install bert-score\n",
        "! pip install bertviz"
      ],
      "id": "307aa482"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4pM0TjpDB9Z"
      },
      "outputs": [],
      "source": [
        "# Connect Code to Google Drive (if necessary)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "gdrive_dir = '/content/drive/MyDrive/CS 282 Project/Checkpoint 2/cs282-project/'"
      ],
      "id": "V4pM0TjpDB9Z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a02a70f"
      },
      "source": [
        "# Configuration"
      ],
      "id": "1a02a70f"
    },
    {
      "cell_type": "code",
      "source": [
        "workdir = gdrive_dir\n",
        "\n",
        "input_filename = 'expanded_all_data.json'\n",
        "\n",
        "# Full DataSet Size is 15000 (review, paper), but due to GPU cost + time constraints, we use a sub-sample of 5000 reviews\n",
        "sample_size = 25 \n",
        "\n",
        "seed = 100\n",
        "\n",
        "# Specify Extraction Method used to Generate Training Text from Papers\n",
        "# Either: (intro, ce_extract, hybrid)\n",
        "extraction_method = 'hybrid'\n",
        "\n",
        "# Maximum Token Length of Paper Extracts Used To Train Model\n",
        "max_paper_extract_length = 1024 # 1024 is the max input size of a BART model\n",
        "max_review_length = 1024\n",
        "min_text_length = 100\n",
        "\n",
        "# Pre-Trained Hugging Face Seq2Seq Transformers Model\n",
        "pre_trained_model_checkpoint = \"facebook/bart-large-cnn\"\n",
        "\n",
        "# Summarization Task Configuration\n",
        "summarization_params = {\n",
        "    \"summarization\": {\n",
        "        \"early_stopping\": True,\n",
        "        \"length_penalty\": 2.0, # BART (favor longer sequences)\n",
        "        \"max_length\": max_review_length,\n",
        "        \"min_length\": min_text_length,\n",
        "        \"no_repeat_ngram_size\": 3, # BART default\n",
        "        \"num_beams\": 4 # BART default\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "GYk-R9PNZhcb"
      },
      "id": "GYk-R9PNZhcb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4d9b322"
      },
      "source": [
        "## Load DataSet"
      ],
      "id": "c4d9b322"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e062c46a"
      },
      "outputs": [],
      "source": [
        "from datasets import concatenate_datasets, DatasetDict, Dataset, load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load input data (post-extraction and pre-processing to downsample paper text)\n",
        "all_input_df = pd.read_json(workdir + input_filename, orient='records')"
      ],
      "id": "e062c46a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Tokenizer For Filtering"
      ],
      "metadata": {
        "id": "Vkc3WgSKgpId"
      },
      "id": "Vkc3WgSKgpId"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load Tokenizer used with the corresponding pre-trained mode\n",
        "tokenizer = AutoTokenizer.from_pretrained(pre_trained_model_checkpoint)"
      ],
      "metadata": {
        "id": "JNFueJSFgwhC"
      },
      "id": "JNFueJSFgwhC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter on token length [not currently used because it decreases the available \n",
        "# dataset size for the CE_extraction method]\n",
        "def filter_on_token_length(df, tokenizer, text_col, text_min=min_text_length, \n",
        "                           text_max=max_paper_extract_length, review_min=min_text_length, \n",
        "                           review_max=max_review_length):\n",
        "    \n",
        "    def test_length_constraints(txt, tokenizer, mn_length, mx_length):\n",
        "        tokenized_txt = tokenizer(txt, max_length=None, truncation=False)\n",
        "        num_tokens = len(tokenized_txt['input_ids'])\n",
        "\n",
        "        return (num_tokens >= mn_length) and (num_tokens <= mx_length)\n",
        "      \n",
        "    return df[\n",
        "              (df[text_col].apply(lambda s: test_length_constraints(s, tokenizer, text_min, text_max))) &\n",
        "              (df['review'].apply(lambda s: test_length_constraints(s, tokenizer, review_min, review_max)))\n",
        "           ]"
      ],
      "metadata": {
        "id": "Sa5oYS5lhPe_"
      },
      "id": "Sa5oYS5lhPe_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e8iFGHozhxZv"
      },
      "id": "e8iFGHozhxZv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filt_input_df = all_input_df # [not currently used] filter_on_token_length(df_exp, tokenizer, extraction_method)\n",
        "if sample_size:\n",
        "    sample_df = filt_input_df.sample(sample_size, random_state=seed)\n",
        "input_dataset = Dataset.from_pandas(sample_df if sample_size else filt_input_df)\n",
        "input_dataset_dict = input_dataset.train_test_split(test_size=0.20)"
      ],
      "metadata": {
        "id": "KuNhPSLohOVZ"
      },
      "id": "KuNhPSLohOVZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d94fb72"
      },
      "outputs": [],
      "source": [
        "input_dataset_dict"
      ],
      "id": "7d94fb72"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b4cddda"
      },
      "source": [
        "## Tokenize DataSet"
      ],
      "id": "6b4cddda"
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function_for_review_task(paper_json, extraction_method='intro'):\n",
        "\n",
        "    if extraction_method == 'intro':\n",
        "        input_text = paper_json['intro']\n",
        "    elif extraction_method == 'ce_extract':\n",
        "        input_text = paper_json['ce_extract']\n",
        "    elif extraction_method == 'hybrid':\n",
        "        input_text = paper_json['ce_extract'] + paper_json['abstract']\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        input_text,\n",
        "        max_length=max_paper_extract_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    labels = tokenizer(\n",
        "        text_target=paper_json[\"review\"], \n",
        "        max_length=max_review_length, truncation=True\n",
        "    )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    # print(len(model_inputs['labels']))\n",
        "    # print(len(paper_json['text']))\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "jPFus8qeo4us"
      },
      "id": "jPFus8qeo4us",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI0JbZ49SoKU"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset_for_reviews = input_dataset_dict.map(lambda s: preprocess_function_for_review_task(s, extraction_method=extraction_method))"
      ],
      "id": "eI0JbZ49SoKU"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset_for_reviews # validate train / test sizes"
      ],
      "metadata": {
        "id": "U7CGDY89bkej"
      },
      "id": "U7CGDY89bkej",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_dataset_for_reviews['train'][0]['input_ids']) # validate that tokenizer creates encoding of expected token length"
      ],
      "metadata": {
        "id": "sggu9SA5PDsl"
      },
      "id": "sggu9SA5PDsl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ac9efc1"
      },
      "source": [
        "# Model Training"
      ],
      "id": "8ac9efc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ed669e0"
      },
      "source": [
        "## Load Pre-Trained Model"
      ],
      "id": "1ed669e0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Last Saved Checkpoint - if training model from previous saved state \n",
        "# model_checkpoint = workdir + 'outputmodel/review_generation/' + extraction_method"
      ],
      "metadata": {
        "id": "7aDgEUGZuCYy"
      },
      "id": "7aDgEUGZuCYy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_checkpoint = workdir + 'outputmodel/review_generation/' + extraction_method"
      ],
      "metadata": {
        "id": "asffPXERJbJ7"
      },
      "id": "asffPXERJbJ7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration\n",
        "\n",
        "# Load Pre-TrainedModel from BART\n",
        "if local_checkpoint:\n",
        "    pre_trained_model_checkpoint = local_checkpoint\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained(pre_trained_model_checkpoint, \n",
        "                                                     max_length=max_review_length, \n",
        "                                                     min_length=min_text_length,\n",
        "                                                     task_specific_params=summarization_params)"
      ],
      "metadata": {
        "id": "oZtFWYch29FF"
      },
      "id": "oZtFWYch29FF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26f8a749"
      },
      "source": [
        "## Fine-Tune Bart Model using Tokenized, Extracted Training Set"
      ],
      "id": "26f8a749"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9af2dd1"
      },
      "source": [
        "### Evaluation Metrics"
      ],
      "id": "c9af2dd1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b004fef3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import sent_tokenize\n",
        "import bert_score\n",
        "import evaluate\n",
        "\n",
        "rouge_score = evaluate.load(\"rouge\")\n",
        "\n",
        "# Compute Evaulation Metric on Seq2Seq Prediction\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Decode generated summaries into text\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    # Decode reference summaries into text\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    # Compute ROUGE scores\n",
        "    rouge_results = rouge_score.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Compute BERT Scores\n",
        "    # https://github.com/Tiiiger/bert_score/blob/master/example/Demo.ipynb\n",
        "    # https://arxiv.org/pdf/1904.09675.pdf\n",
        "    unscaled_bert_scores = bert_score.score(decoded_preds, decoded_labels, lang='en', \n",
        "                                   verbose=False, rescale_with_baseline=False)\n",
        "    bs_prec, bs_recall, bs_f1 = (unscaled_bert_scores[0].mean(), \n",
        "                                 unscaled_bert_scores[1].mean(), \n",
        "                                 unscaled_bert_scores[2].mean())\n",
        "\n",
        "    # Extract the median scores\n",
        "    results = {k: round(v, 4) for k, v in rouge_results.items()}\n",
        "    \n",
        "    results.update({'Raw_BertScore_F1_mean': bs_f1, \n",
        "                    'Raw_BertScore_Recall_mean': bs_recall,\n",
        "                    'Raw_BertScore_Precision_mean': bs_prec,\n",
        "                    })\n",
        "    \n",
        "    scaled_bert_scores = bert_score.score(decoded_preds, decoded_labels, lang='en', \n",
        "                                   verbose=False, rescale_with_baseline=True)\n",
        "    bs_prec, bs_recall, bs_f1 = (scaled_bert_scores[0].mean(), \n",
        "                                 scaled_bert_scores[1].mean(), \n",
        "                                 scaled_bert_scores[2].mean())\n",
        "\n",
        "    results.update({'Scaled_BertScore_F1_mean': bs_f1, \n",
        "                    'Scaled_BertScore_Recall_mean': bs_recall,\n",
        "                    'Scaled_BertScore_Precision_mean': bs_prec,\n",
        "                    })\n",
        "\n",
        "    return results"
      ],
      "id": "b004fef3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92b005e6"
      },
      "source": [
        "### Training Arguments"
      ],
      "id": "92b005e6"
    },
    {
      "cell_type": "code",
      "source": [
        "## Hyperparameters\n",
        "# Selected based on Hugging Face Guide & Confirmed with validation on small samples\n",
        "num_train_epochs = 1\n",
        "learning_rate = 5.0e-5\n",
        "weight_decay = 0.001"
      ],
      "metadata": {
        "id": "Cz0cI5r4bdGX"
      },
      "id": "Cz0cI5r4bdGX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "629fd8ef"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "# Max Batch Size supported by GPU\n",
        "batch_size = 1\n",
        "\n",
        "# Show the training loss with every epoch\n",
        "logging_steps = len(tokenized_dataset_for_reviews[\"train\"]) // batch_size \n",
        "\n",
        "model_name = 'outputmodel/review_generation/' + extraction_method\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\" # disable wandb\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir= workdir + model_name,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=weight_decay,\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=2,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    predict_with_generate=True, \n",
        "    generation_max_length=max_review_length, \n",
        "    logging_steps=logging_steps,\n",
        "    report_to=None \n",
        ")"
      ],
      "id": "629fd8ef"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e5cc1e1"
      },
      "source": [
        "### Training Function"
      ],
      "id": "9e5cc1e1"
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import gc\n",
        "\n",
        "# del trainer\n",
        "# torch.cuda.empty_cache()\n",
        "# gc.collect()\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "id": "1U9mvQHhZ-99"
      },
      "id": "1U9mvQHhZ-99",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8a46a46"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# Set Up Model Training\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_dataset_for_reviews[\"train\"],\n",
        "    eval_dataset=tokenized_dataset_for_reviews[\"test\"],\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train Model on Tokenized DataSet\n",
        "trainer.train()\n",
        "\n",
        "# Save Model\n",
        "trainer.save_model()"
      ],
      "id": "e8a46a46"
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenized_dataset_for_reviews['train'][0:5]"
      ],
      "metadata": {
        "id": "9PK_uou0GDhV"
      },
      "id": "9PK_uou0GDhV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85b7553a"
      },
      "source": [
        "## Evaluate Model"
      ],
      "id": "85b7553a"
    },
    {
      "cell_type": "code",
      "source": [
        "txt = tokenized_dataset_for_reviews['train'][0][extraction_method]"
      ],
      "metadata": {
        "id": "tD0_S9_Rq3ko"
      },
      "id": "tD0_S9_Rq3ko",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(workdir + model_name)\n",
        "inputs = tokenizer(txt, return_tensors=\"pt\", truncation=True).input_ids\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(workdir + model_name)\n",
        "outputs = model.generate(inputs)\n",
        "\n",
        "decoded_output = \"\"\n",
        "for output in outputs:\n",
        "  decoded_output += tokenizer.decode(output, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "nUAddTjfZw8t"
      },
      "id": "nUAddTjfZw8t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoded_output)"
      ],
      "metadata": {
        "id": "DTob7GVRrcDR"
      },
      "id": "DTob7GVRrcDR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preds = trainer.predict(tokenized_dataset_for_reviews['test'])"
      ],
      "metadata": {
        "id": "i8bElggxL3lY"
      },
      "id": "i8bElggxL3lY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4ab00c9"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ],
      "id": "c4ab00c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8ZXgm1_ZToU"
      },
      "outputs": [],
      "source": [
        "model = trainer.model"
      ],
      "id": "q8ZXgm1_ZToU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-s8fWhhdUmP"
      },
      "outputs": [],
      "source": [
        "preds = trainer.predict(tokenized_dataset['train'])"
      ],
      "id": "3-s8fWhhdUmP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdxGHFJta1fG"
      },
      "outputs": [],
      "source": [
        "newmodel = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
        "print(newmodel)"
      ],
      "id": "WdxGHFJta1fG"
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_txt.encodings[0].tokens)\n",
        "len(tokenized_txt.encodings[0].attention_mask)\n",
        "tokenized_txt = tokenizer(txt)"
      ],
      "metadata": {
        "id": "B1q_L2oDn6Dc"
      },
      "id": "B1q_L2oDn6Dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_text = input_df.head(1)['hybrid'].values[0]\n",
        "# review =  input_df.head(1)['review'].values[0]\n",
        "# model_inputs = tokenizer(\n",
        "#         input_text,\n",
        "#         max_length=max_paper_extract_length,\n",
        "#         truncation=True,\n",
        "#     )\n",
        "\n",
        "# labels = tokenizer(\n",
        "#     text_target=review, max_length=max_review_length, truncation=True\n",
        "# )\n",
        "# model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "# # print(len(model_inputs['labels']))\n",
        "# # print(len(paper_json['text']))"
      ],
      "metadata": {
        "id": "KpFiYuMLqWPh"
      },
      "id": "KpFiYuMLqWPh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration\n",
        "from transformers import LongformerConfig, LongformerModel\n",
        "\n",
        "# Initializing a Longformer configuration\n",
        "configuration = LongformerConfig()\n",
        "\n",
        "# Initializing a model from the configuration\n",
        "model = LongformerModel(configuration)\n",
        "\n",
        "# Accessing the model configuration\n",
        "configuration = model.config"
      ],
      "metadata": {
        "id": "zlyVaIoGqNto"
      },
      "id": "zlyVaIoGqNto",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the token length exceeds 1024, which is the maximum input size for BART, so some of the input will be truncated. We were surprised that this was teh case for the cross-entropy inputs, since we used the authors default configuration for downsampling the paper to an input text and the authors state that they use BART for their Seq2Seq models. It's possible that they are using another tokenizer.\n",
        "\n",
        "In any case, due to time constraints (of re-running cross-entropy extraction and/or determining a different tokenizer/vocabulary file to use), we truncate inputs for now and leave further investigation to the next steps. "
      ],
      "metadata": {
        "id": "os3wpntP4vRI"
      },
      "id": "os3wpntP4vRI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33564052"
      },
      "source": [
        "# Reproduce Results"
      ],
      "id": "33564052"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KOEQBWMTSaz"
      },
      "outputs": [],
      "source": [
        "# Linear Model On Top of Custom Model"
      ],
      "id": "1KOEQBWMTSaz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysgPaVHsRjY8"
      },
      "outputs": [],
      "source": [
        "# Aspect Scores"
      ],
      "id": "ysgPaVHsRjY8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJmHTCPxT4dF"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate[torch]\n",
        "!pip3 install torch torchvision"
      ],
      "id": "OJmHTCPxT4dF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fxlXcPWT3QK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "# from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from collections import OrderedDict\n",
        "from accelerate import Accelerator"
      ],
      "id": "5fxlXcPWT3QK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-fXJ-FMR39Z"
      },
      "outputs": [],
      "source": [
        "class CustomModel(nn.Module):\n",
        "  def __init__(self, checkpoint, num_labels): \n",
        "    super(CustomModel,self).__init__() \n",
        "    self.num_labels = num_labels \n",
        "\n",
        "    #Load Model with given checkpoint and extract its body\n",
        "    self.model = model = AutoModel.from_pretrained(checkpoint,config=AutoConfig.from_pretrained(checkpoint))\n",
        "    self.dropout = nn.Dropout(0.1) \n",
        "    self.classifier = nn.Linear(768, num_labels) # load and initialize weights\n",
        "\n",
        "  def forward(self, input_ids=None, attention_mask=None,labels=None):\n",
        "    #Extract outputs from the body\n",
        "    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    #Add custom layers\n",
        "    sequence_output = self.dropout(outputs[0]) #outputs[0]=last hidden state\n",
        "\n",
        "    logits = self.classifier(sequence_output[:,0,:].view(-1,768)) # calculate losses\n",
        "    \n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "    \n",
        "    return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states,attentions=outputs.attentions)"
      ],
      "id": "p-fXJ-FMR39Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBEZINZ4Ye5Q"
      },
      "outputs": [],
      "source": [
        "def train_model(model, epochs=None, debug=False):\n",
        "    \"\"\" Train a model. \"\"\"\n",
        "    config = get_model_configuration()\n",
        "    loss_function = config.get(\"loss_function\")()\n",
        "    optimizer = config.get(\"optimizer\")(model.parameters(), lr=1e-4)\n",
        "    trainloader = get_dataset()\n",
        "    accelerator = Accelerator()  \n",
        "\n",
        "    # Accelerate model\n",
        "    model, optimizer, trainloader = accelerator.prepare(model, optimizer, trainloader)\n",
        "\n",
        "    # Iterate over the number of epochs\n",
        "    entries = []\n",
        "    \n",
        "    if epochs is None:\n",
        "        epochs = config.get(\"num_epochs\")\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Print epoch\n",
        "        print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "        # Set current loss value\n",
        "        current_loss = 0.0\n",
        "        \n",
        "        output_data = []\n",
        "        targets_data = []\n",
        " \n",
        "        # Iterate over the DataLoader for training data\n",
        "        st_time = time.time()\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "#             print(i)\n",
        "\n",
        "            # Get inputs\n",
        "            inputs, targets = data\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Perform forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "#             print(outputs)\n",
        "#             print(outputs.shape)\n",
        "#             print(targets)\n",
        "#             print(targets.shape)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            \n",
        "            output_data.extend(outputs.cpu().detach().numpy())\n",
        "            targets_data.extend(targets.cpu().detach().numpy())\n",
        "            current_loss += loss.item()\n",
        "            \n",
        "            # Perform backward pass\n",
        "            accelerator.backward(loss)\n",
        "\n",
        "            # Perform optimization\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Print statistics\n",
        "            if debug:\n",
        "                print('Loss after mini-batch %5d: %.3f' %\n",
        "                    (i + 1, current_loss / 500))\n",
        "\n",
        "        end_time = time.time()\n",
        "        \n",
        "        train_entry = {'type': 'train', 'epoch': epoch, \n",
        "                       'loss': current_loss, 'time': round(end_time - st_time, 1)}\n",
        "        \n",
        "        \n",
        "        print(f'Loss: {current_loss}')\n",
        "        \n",
        "        test_entry = {'type': 'test', 'epoch': epoch, 'loss': test_loss}\n",
        "        \n",
        "        entries.extend([train_entry, test_entry])\n",
        "\n",
        "    # Return trained model\n",
        "    return model, pd.DataFrame(entries), current_loss"
      ],
      "id": "xBEZINZ4Ye5Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56da4849"
      },
      "outputs": [],
      "source": [
        "## Load Data "
      ],
      "id": "56da4849"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Attention Maps"
      ],
      "metadata": {
        "id": "33hubwPfLK4L"
      },
      "id": "33hubwPfLK4L"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "Wm_7JXPnb_3n"
      },
      "id": "Wm_7JXPnb_3n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Load pre-trained model + tokenizer"
      ],
      "metadata": {
        "id": "62-8IWf7LQmQ"
      },
      "id": "62-8IWf7LQmQ"
    },
    {
      "cell_type": "code",
      "source": [
        "local_checkpoint = workdir + 'outputmodel/review_generation/' + extraction_method\n",
        "\n",
        "# Load Tokenizer used with the corresponding pre-trained mode\n",
        "tokenizer = AutoTokenizer.from_pretrained(pre_trained_model_checkpoint)\n",
        "\n",
        "# Load Pre-TrainedModel from BART\n",
        "if local_checkpoint:\n",
        "    pre_trained_model_checkpoint = local_checkpoint\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained(pre_trained_model_checkpoint, \n",
        "                                                     max_length=max_review_length, \n",
        "                                                     min_length=min_text_length,\n",
        "                                                     task_specific_params=summarization_params)"
      ],
      "metadata": {
        "id": "YDFJRCwcLMyc"
      },
      "id": "YDFJRCwcLMyc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use BertViz package to create attention maps"
      ],
      "metadata": {
        "id": "ZkmlIZ3kLYB6"
      },
      "id": "ZkmlIZ3kLYB6"
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoder_input_ids[0])"
      ],
      "metadata": {
        "id": "k-XUsi7Mea_L"
      },
      "id": "k-XUsi7Mea_L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt[0:2000]"
      ],
      "metadata": {
        "id": "m5MUFLYjewRe"
      },
      "id": "m5MUFLYjewRe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the inputs and compute attention\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
        "# model = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\", output_attentions=True)\n",
        "\n",
        "encoder_input_ids = tokenizer(txt[0:2000], return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
        "with tokenizer.as_target_tokenizer():\n",
        "    decoder_input_ids = tokenizer(decoded_output, return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
        "\n",
        "outputs = model(input_ids=encoder_input_ids, decoder_input_ids=decoder_input_ids)\n",
        "\n",
        "encoder_text = tokenizer.convert_ids_to_tokens(encoder_input_ids[0])\n",
        "decoder_text = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])"
      ],
      "metadata": {
        "id": "Y8fqhLTNLid8"
      },
      "id": "Y8fqhLTNLid8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = tokenized_dataset_for_reviews['train'][0][extraction_method]\n",
        "inputs = tokenizer(txt, return_tensors=\"pt\", truncation=True).input_ids\n",
        "\n",
        "model_name = 'outputmodel/review_generation/' + extraction_method\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(workdir + model_name)\n",
        "outputs = model.generate(inputs)\n",
        "\n",
        "decoded_output = \"\"\n",
        "for output in outputs:\n",
        "  decoded_output += tokenizer.decode(output, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "DttZpU-fNzf-"
      },
      "id": "DttZpU-fNzf-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the visualization using either head_view or model_view\n",
        "from bertviz import model_view\n",
        "model_view(encoder_attention=outputs.encoder_attentions, decoder_attention=outputs.decoder_attentions, cross_attention=outputs.cross_attentions, encoder_tokens= encoder_text, decoder_tokens = decoder_text)"
      ],
      "metadata": {
        "id": "U2Pee1CIL9EQ"
      },
      "id": "U2Pee1CIL9EQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel, utils\n",
        "from bertviz import model_view\n",
        "\n",
        "utils.logging.set_verbosity_error()  # Remove line to see warnings\n",
        "\n",
        "# Initialize tokenizer and model. Be sure to set output_attentions=True.\n",
        "# Load BART fine-tuned for summarization on CNN/Daily Mail dataset\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name, output_attentions=True)\n",
        "\n",
        "# get encoded input vectors\n",
        "encoder_input_ids = tokenizer(\"The House Budget Committee voted Saturday to pass a $3.5 trillion spending bill\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
        "\n",
        "# create ids of encoded input vectors\n",
        "decoder_input_ids = tokenizer(\"The House Budget Committee passed a spending bill.\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
        "\n",
        "outputs = model(input_ids=encoder_input_ids, decoder_input_ids=decoder_input_ids)\n",
        "\n",
        "encoder_text = tokenizer.convert_ids_to_tokens(encoder_input_ids[0])\n",
        "decoder_text = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])\n",
        "\n",
        "model_view(\n",
        "    encoder_attention=outputs.encoder_attentions,\n",
        "    decoder_attention=outputs.decoder_attentions,\n",
        "    cross_attention=outputs.cross_attentions,\n",
        "    encoder_tokens= encoder_text,\n",
        "    decoder_tokens=decoder_text\n",
        ")"
      ],
      "metadata": {
        "id": "CYMo9DEfNvr6"
      },
      "id": "CYMo9DEfNvr6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9i1ayD6yfpyy"
      },
      "id": "9i1ayD6yfpyy",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}